--- This file contains information about CockroachDB (CRDB) which I could record ----

-What features are difficult for application developers to implement with traditional SQL databases?
 - Availability
 - Scalability
   Explanation:
   Traditional SQL databases delivered ACID transactions and joins easily, but scalability and high availability were difficult to implement.
       --ACID transactions are database operations ensuring reliability and data integrity through four key properties: Atomicity (all-or-nothing), Consistency (valid data states), Isolation (concurrent operations don't interfere), and Durability (committed changes are permanent)
       When someone says ACID guarantees, they're talking about four promises.
          -First,  transaction has to be atomic, meaning that all parts of the transaction happen or none.
          -Second, they have to be consistent, which in this context means the transaction has to respect any rules imposed on the database like foreign key constraints, and move from one consistent state to another with no inconsistent states visible to any readers at any time.
          -Third, they have to be isolated, meaning that even though the database might be able to parallelize some operations, it can't permit it to look like they're interleaved.
          -Finally, they have to be durable.
           When a transaction is committed, it stays committed even in the face of node failure.
       --Joins are fundamental commands in database management (SQL) that combine rows from two or more tables based on related columns, creating a new, unified result set for querying data that spans multiple tables, like linking customers to their orders.

--- Distributed SQL, must comply with this set of characteristics:
 - Scale
 - Consistency
 - Resiliency
 - SQL (must use this language)

--- NoSQL vs Legacy SQL
                   Scale  query by SQL  Consistency  Resiliency
    NoSQL           Yes      No            No           Yes
    Legacy SQL      No       Yes           Yes          No

---What Cockroach Delivers:
   -ACID Transactions
   -PostgreSQL wire protocol
   -Geo-replication
   -Multi-cloud
   -Advanced admin tools
   -Optimization
   -Baked in security

-- These are some of the features of CRDB:
 - Transactions
 - Geo-replication
 - High availability
 - Scalability

-- CRDB uses serializable isolation level.

------Cluster Concepts ----
 - Basic Model of Cluster Data: Keyspace
 - Keyspace is divided into ranges, by default 64MB in size but on version 20.1 this default changed to 512MB
 - Ranges are units that CockroachDB replicates and distributes to the nodes of the cluster
 - Replicas = copies of ranges, up to a replication factor
 - Replication Factor = How many times a range is replicated in a cluster
 - Replicas distributed among nodes of cluster

------The Raft Protocol in CockroachDB ----
 - CockroachDB uses the Raft Protocol to perform writes in a distributed and durable manner.
 - Raft is an algorithm that allows a distributed set of servers to agree on any values without losing the record of that value, even in the face of node failure. CockroachDB uses it to perform all writes.

-Recall that CockroachDB organizes its data into a keyspace, divided into ranges and distributes replicas of each range throughout the cluster based on the replication factor.
 - For CockroachDB, each range defines a Raft group.
 - The cluster has seven ranges, so there will be seven raft groups.

-CockroachDB has a concept of something called a lease, which it assigns to one of these replicas called the leaseholder. Its job will be to serve reads on its own bypassing Raft but also keeping track of write commits, so it knows not to show rights until they're durable.
  1.- Let's put a lease on one of those replicas.
  2.- Now all reads and writes to the range will be sent to that node.

- Raft. The first thing to know about Raft is that 
  - replicas are either leaders or followers.
    - Leaders coordinate the distributed write process while followers assist.
      If a follower doesn't see a heartbeat from a leader, it'll get a randomized time-out, declare itself a candidate, and call for an election. Majority vote makes it a leader. The process takes seconds.
  3.- Let's elect a leader.
      I made the leader the same as the leaseholder, and while they're different roles, in practice, CockroachDB does a good job of keeping the lease with the leader for efficiency. So we'll assume that scenario.
  4.- Writes are kicked off by the leaseholders which tells the leader to begin the process.
  5.- Here's an insert.
  6.- The leader first upends the command to its Raft log, which is an ordered set of commands on disc.
  7.- The leader then proposes the write to the followers.
  8.- Each follower will replicate the command on its own Raft log.
I showed only one replication so far since that's enough for a majority. Even without hitting the third node, the write will persist through any single node failure.
  9.- Consensus has been achieved, but the leader doesn't know that yet. So the follower has to let it know.
 10.- At this point, the leader knows the Raft command was replicated so it can commit the write and notify the leaseholder to begin showing it to readers.
 11.- Eventually, that write will go to every replica.
Let's look at our full cluster with a leader for each range to get a big picture sense of things. Here, each range has one replica. That's its leader and its leaseholder. All sequel operations are routed to the appropriate leaseholders. Reads are returned while writes are passed to the leaders to start building consensus.
So, what have we learned? We've seen that the leaseholder ensures that readers only see committed writes, and that replicas arranged together form a Raft group that elects one leader.
We've seen how a distributed consensus is achieved for writes, and that's how Raft works in CockroachDB. 

 In a Raft group, how many copies of a Raft Log entry must exist for a write to be committed?
 Enough to be on a majority of the Raft group

 What happens when a single node goes down?
 Leaseholders, if present on a node, will move.

 
--Resiliency in Large Clusters --

 When can a cluster heal its way out of a fragile state (one with under-replicated ranges)?
 When it has enough nodes to up-replicate the under-replicated ranges


----------Getting a local single node cluster going----------------

 Command:
 $ cockroach start-single-node --insecure --listen-addr=localhost:26257 --http-addr=localhost:8080
   --> --insecure ==> no encryption or authentication, not for production!!
   --> --http-addr=localhost:8080 ==> where we can see the admin UI to get visibility into the cluster
   --> --listen-addr=localhost:26257 ==> where/what port the node should listen for connections
 
 ---To stop the cluster just hit Ctrl+c

    Another command that also works is:
    $ cockroach start-single-node --insecure --listen-addr localhost

    This give the exact same result as the previous but assumes default parameters for the ports by only 
    specifying "localhost"

-----------Use SQL Shell to create and modify Tables-------------

 > Connect to cluster using SQL shell:
 
   $ cockroach sql --insecure
    This connects to the cluster in the local host that was created

 > Some SQL commands that are usefull for manipulating and going through the cluster
   
   Example of how the prompt will look like inthe SQL shell:

         root@localhost:26257/defaultdb>
   
   This means you are logged in as root and connecting through the localhost on port 26257 
   and on the defaultdb database.

   >> SHOW DATABASES;  ---> Showw all the databases in the cluster
    Ex.

root@localhost:26257/defaultdb> SHOW DATABASES;                                             
  database_name | owner | primary_region | secondary_region | regions | survival_goal
----------------+-------+----------------+------------------+---------+----------------
  defaultdb     | root  | NULL           | NULL             | {}      | NULL
  postgres      | root  | NULL           | NULL             | {}      | NULL
  system        | node  | NULL           | NULL             | {}      | NULL
(3 rows)

Time: 6ms total (execution 5ms / network 0ms)


    
    >> CREATE DATABASE <database name>;  ---> create a new database 
    Ex.

root@localhost:26257/defaultdb> CREATE DATABASE crdb_uni;                                   
CREATE DATABASE

Time: 86ms total (execution 80ms / network 6ms)

root@localhost:26257/defaultdb> SHOW DATABASES;                                             
  database_name | owner | primary_region | secondary_region | regions | survival_goal
----------------+-------+----------------+------------------+---------+----------------
  crdb_uni      | root  | NULL           | NULL             | {}      | NULL
  defaultdb     | root  | NULL           | NULL             | {}      | NULL
  postgres      | root  | NULL           | NULL             | {}      | NULL
  system        | node  | NULL           | NULL             | {}      | NULL
(4 rows)


   >> SET database = <database name>; ------> change into another database
   Ex.

root@localhost:26257/defaultdb> SET database = crdb_uni;                                    
SET

Time: 2ms total (execution 1ms / network 1ms)

root@localhost:26257/crdb_uni>        

   >> CREATE TABLE students (id UUID PRIMARY KEY DEFAULT gen_random_uuid(), name STRING);
      This creates a table with two columns id and name.
      The id column needs to have certain properties:
        - UUID. The values on the id column need to be the univarsally unique identifier data
          type,
          or UUID
        - PRIMARY KEY. This column is the PRIMARY KEY for the table, which specifies the 
          values must uniquely idenfy each row. The columns in the PRIMARY KEY constraint are
          used to create its primary index, which CockroachDB uses, by default, to access the           table's data.
        - DEFAULT gen_random_uuid(). Specify that if the value is not provided for a row's ID,
          the default value is an an auto-generated random UUID.
   >> SHOW CREATE students;  ---> this shows the schema and properties of the table
   >>
CREATE TABLE courses (sys_id UUID DEFAULT gen_random_uuid(), course_id INT, name STRING, PRIMARY KEY (sys_id, course_id));
SHOW CREATE TABLE courses;
ALTER TABLE courses ADD COLUMN schedule STRING;
SHOW CREATE TABLE courses;
